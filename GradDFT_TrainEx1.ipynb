{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGZa5hkIx1tm2E489HWj2/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkk020719/DFT_Fall24/blob/main/GradDFT_TrainEx1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6R0q3q7WCGdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "bb1ddbfc-b10b-422c-e53a-91a984a70146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/XanaduAI/GradDFT.git\n",
            "  Cloning https://github.com/XanaduAI/GradDFT.git to /tmp/pip-req-build-n3sv9v5o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/XanaduAI/GradDFT.git /tmp/pip-req-build-n3sv9v5o\n",
            "  Resolved https://github.com/XanaduAI/GradDFT.git to commit 941afc28a6b24477369d638b07ca64c6a46365ba\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (0.4.33)\n",
            "Collecting pyscf>=2.3.0 (from grad_dft==0.1)\n",
            "  Downloading pyscf-2.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (24.2.0)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (0.8.5)\n",
            "Collecting tensorflow<=2.14.0,>=2.13.0 (from grad_dft==0.1)\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (0.16.1)\n",
            "Collecting typeguard==2.13.3 (from grad_dft==0.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (4.12.2)\n",
            "Collecting jaxtyping (from grad_dft==0.1)\n",
            "  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pytest>=7.4.3 in /usr/local/lib/python3.10/dist-packages (from grad_dft==0.1) (7.4.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (1.26.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (0.2.3)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (0.1.66)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (13.9.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->grad_dft==0.1) (6.0.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->grad_dft==0.1) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->grad_dft==0.1) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->grad_dft==0.1) (1.13.1)\n",
            "Requirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.10/dist-packages (from pyscf>=2.3.0->grad_dft==0.1) (3.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyscf>=2.3.0->grad_dft==0.1) (75.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=7.4.3->grad_dft==0.1) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest>=7.4.3->grad_dft==0.1) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.4.3->grad_dft==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.4.3->grad_dft==0.1) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.4.3->grad_dft==0.1) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (18.1.1)\n",
            "Collecting ml-dtypes>=0.2.0 (from jax>=0.4.14->grad_dft==0.1)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (2.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (1.64.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.14.0->grad_dft==0.1) (2.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.44.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->grad_dft==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->grad_dft==0.1) (2.18.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.0.4)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.14.0->grad_dft==0.1)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->grad_dft==0.1) (0.1.87)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->grad_dft==0.1) (1.9.4)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->grad_dft==0.1) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->grad_dft==0.1) (4.10.0)\n",
            "INFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorstore (from flax>=0.7.2->grad_dft==0.1)\n",
            "  Downloading tensorstore-0.1.65-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.64-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.63-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.62-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.61-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting orbax-checkpoint (from flax>=0.7.2->grad_dft==0.1)\n",
            "  Downloading orbax_checkpoint-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "INFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting tensorstore (from flax>=0.7.2->grad_dft==0.1)\n",
            "  Downloading tensorstore-0.1.59-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.58-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.57-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.56-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.55-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.54-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.53-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.52-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.51-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.50-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.49-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading tensorstore-0.1.48-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorstore-0.1.47-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorstore-0.1.46-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting jax>=0.4.14 (from grad_dft==0.1)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib>=0.4.14 (from grad_dft==0.1)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting orbax-checkpoint (from flax>=0.7.2->grad_dft==0.1)\n",
            "  Downloading orbax_checkpoint-0.6.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.6.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.6.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.6.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.23-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.22-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.21-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.18-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.17-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.16-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.15-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.14-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.13-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.12-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.10-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading orbax_checkpoint-0.5.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.6-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->flax>=0.7.2->grad_dft==0.1) (0.12.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->grad_dft==0.1) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.0.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->grad_dft==0.1) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->grad_dft==0.1) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->grad_dft==0.1) (3.20.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<=2.14.0,>=2.13.0->grad_dft==0.1) (3.2.2)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading pyscf-2.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: grad_dft\n",
            "  Building wheel for grad_dft (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad_dft: filename=grad_dft-0.1-py3-none-any.whl size=105939 sha256=ae0105ef39df23c1f81c147991590e52d910d34d2257bb21697a0b7a18571edc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yf9yxncr/wheels/2d/6e/fe/1e41b72a240125d52eebf283162347be333a53170769f20484\n",
            "Successfully built grad_dft\n",
            "Installing collected packages: wrapt, typeguard, tf-keras, tensorstore, tensorflow-estimator, ml-dtypes, keras, pyscf, jaxtyping, google-auth-oauthlib, tensorboard, orbax-checkpoint, tensorflow, grad_dft\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorstore\n",
            "    Found existing installation: tensorstore 0.1.66\n",
            "    Uninstalling tensorstore-0.1.66:\n",
            "      Successfully uninstalled tensorstore-0.1.66\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: orbax-checkpoint\n",
            "    Found existing installation: orbax-checkpoint 0.6.4\n",
            "    Uninstalling orbax-checkpoint-0.6.4:\n",
            "      Successfully uninstalled orbax-checkpoint-0.6.4\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 grad_dft-0.1 jaxtyping-0.2.34 keras-2.14.0 ml-dtypes-0.2.0 orbax-checkpoint-0.4.4 pyscf-2.7.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorstore-0.1.45 tf-keras-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Collecting jax==0.4.20\n",
            "  Downloading jax-0.4.20-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting jaxlib==0.4.20\n",
            "  Downloading jaxlib-0.4.20-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.20) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.20) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.20) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.20) (1.13.1)\n",
            "Downloading jax-0.4.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.20-cp310-cp310-manylinux2014_x86_64.whl (85.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.20 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.20 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.20 which is incompatible.\n",
            "optax 0.2.3 requires jax>=0.4.27, but you have jax 0.4.20 which is incompatible.\n",
            "optax 0.2.3 requires jaxlib>=0.4.27, but you have jaxlib 0.4.20 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.20 jaxlib-0.4.20\n",
            "jax                                0.4.20\n",
            "jax-cuda12-pjrt                    0.4.33\n",
            "jax-cuda12-plugin                  0.4.33\n",
            "jaxlib                             0.4.20\n",
            "jaxtyping                          0.2.34\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/XanaduAI/GradDFT.git\n",
        "!pip install torch_geometric\n",
        "!pip install jax==0.4.20 jaxlib==0.4.20\n",
        "!pip list | grep jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "\n",
        "# Mount Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder in the root directory\n",
        "#!mkdir -p \"/content/drive/My Drive/Ethanol_data_MD17\""
      ],
      "metadata": {
        "id": "BhojIuJmH-vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import md17\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "import math\n",
        "import pdb\n",
        "import numpy as np\n",
        "\n",
        "from grad_dft import (\n",
        "\tenergy_predictor,\n",
        "\tsimple_energy_loss,\n",
        "\tNeuralFunctional,\n",
        "\tmolecule_from_pyscf,\n",
        "  Functional\n",
        ")\n",
        "\n",
        "from pyscf import gto, dft\n",
        "\n",
        "from jax.nn import sigmoid, gelu\n",
        "from jax.random import PRNGKey\n",
        "from jax import value_and_grad\n",
        "from flax import linen as nn\n",
        "from optax import adam, apply_updates\n",
        "from tqdm import tqdm\n",
        "from jax.flatten_util import ravel_pytree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from grad_dft import constraints\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fYBhdfQGEBDX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethanol_dataset = md17.MD17(root='.', name='ethanol')"
      ],
      "metadata": {
        "id": "l34ev20wTnr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Energy of the Molecule:\")\n",
        "print(ethanol_data.energy / 627.509)  # This will print the energy of the molecule."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fROS_gVGEG7",
        "outputId": "b2df9945-7e9c-40dc-9cd0-fe75b762879f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cartesian Positions of Atoms:\n",
            "tensor([[ 2.1540e-02, -5.5601e-01,  7.0714e-04],\n",
            "        [-1.2741e+00,  2.4780e-01,  5.0275e-03],\n",
            "        [ 1.1265e+00,  3.1391e-01, -3.5790e-03],\n",
            "        [ 5.9397e-02, -1.2191e+00,  8.8888e-01],\n",
            "        [-8.4126e-02, -1.1607e+00, -8.8107e-01],\n",
            "        [-1.4003e+00,  8.4873e-01,  8.7578e-01],\n",
            "        [-1.3232e+00,  8.5038e-01, -9.2045e-01],\n",
            "        [-2.1540e+00, -4.2816e-01, -2.1951e-02],\n",
            "        [ 1.9455e+00, -2.0287e-01,  4.7284e-02]])\n",
            "Atomic Numbers:\n",
            "tensor([6, 6, 8, 1, 1, 1, 1, 1, 1])\n",
            "<built-in method item of Tensor object at 0x7e955d8632e0>\n",
            "Energy of the Molecule:\n",
            "tensor([-154.9091])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_data(num_data, data_set, atomic_symbols):\n",
        "  'Takes a number of molecules randomly from dataset provided and returning the PySCF molecule objects'\n",
        "  molecules = []\n",
        "  #Randomly select a number of indices\n",
        "  indices = np.random.choice(len(data_set), num_data, replace=False)\n",
        "  selected_samples = [data_set[i] for i in indices]\n",
        "  # Define atomic symbols for the corresponding atomic numbers in MD17 dataset for ethanol\n",
        "  for sample in selected_samples:\n",
        "    position = sample.pos\n",
        "    atomic_number = sample.z\n",
        "\n",
        "    # Start building the molecule description string\n",
        "    atom_desc = ''\n",
        "    for z, pos in zip(atomic_number, position):\n",
        "      #print(z.item())\n",
        "      #print(pos)\n",
        "      if z.item() in atomic_symbols:\n",
        "        symbol = atomic_symbols[z.item()]  # Get symbol using atomic number\n",
        "        atom_desc += f'{symbol} {pos[0]:.4f} {pos[1]:.4f} {pos[2]:.4f}\\n'\n",
        "      else:\n",
        "        raise ValueError(f\"Unrecognized atomic number {z.item()} found, unable to proceed with molecule creation.\")\n",
        "    # Create a PySCF molecule object\n",
        "    mol = gto.M(atom=atom_desc, basis='def2-svp', unit='Ang', spin = 0, verbose=0)\n",
        "    molecules.append(mol)\n",
        "\n",
        "  return molecules\n",
        "\n",
        "#loading PySCF data\n",
        "ethanol_atomic_symbols = {1: 'H', 6: 'C', 8: 'O'}\n",
        "molecule_data = obtain_data(5, ethanol_dataset, ethanol_atomic_symbols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5bympRlKJ5o1",
        "outputId": "ef172954-830c-4c07-ec8f-547ee106442c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "tensor([ 0.3317, -0.1047, -0.4598])\n",
            "6\n",
            "tensor([-0.6103,  1.2270, -0.2505])\n",
            "8\n",
            "tensor([ 0.3106, -1.0113,  0.6711])\n",
            "1\n",
            "tensor([ 0.0316, -0.7746, -1.3801])\n",
            "1\n",
            "tensor([ 1.2824,  0.3131, -0.5983])\n",
            "1\n",
            "tensor([-0.6176,  1.6228, -1.2530])\n",
            "1\n",
            "tensor([-1.6455,  1.0740,  0.0527])\n",
            "1\n",
            "tensor([-0.1555,  1.8640,  0.5676])\n",
            "1\n",
            "tensor([-0.5076, -1.4226,  0.4243])\n",
            "6\n",
            "tensor([ 0.2285, -0.2704, -0.5515])\n",
            "6\n",
            "tensor([-1.2001,  0.0409, -0.1163])\n",
            "8\n",
            "tensor([0.8722, 0.2228, 0.6161])\n",
            "1\n",
            "tensor([ 0.2030, -1.3997, -0.7283])\n",
            "1\n",
            "tensor([ 0.4694,  0.3404, -1.4034])\n",
            "1\n",
            "tensor([-1.6763,  1.0278, -0.3847])\n",
            "1\n",
            "tensor([-1.8741, -0.5672, -0.7293])\n",
            "1\n",
            "tensor([-1.2751, -0.3966,  0.9044])\n",
            "1\n",
            "tensor([1.8848, 0.1920, 0.5194])\n",
            "6\n",
            "tensor([ 0.3055, -0.0737, -0.3709])\n",
            "6\n",
            "tensor([-0.5883,  1.2250, -0.2782])\n",
            "8\n",
            "tensor([ 0.3266, -1.0564,  0.6191])\n",
            "1\n",
            "tensor([-0.0695, -0.5220, -1.3428])\n",
            "1\n",
            "tensor([ 1.3176,  0.2321, -0.5746])\n",
            "1\n",
            "tensor([-0.6452,  1.6442, -1.3135])\n",
            "1\n",
            "tensor([-1.5745,  0.7881, -0.0924])\n",
            "1\n",
            "tensor([-0.2758,  2.0419,  0.3108])\n",
            "1\n",
            "tensor([-0.5680, -1.1357,  0.9200])\n",
            "6\n",
            "tensor([-0.1035, -0.1404,  0.5271])\n",
            "6\n",
            "tensor([-1.1035,  0.6711, -0.2499])\n",
            "8\n",
            "tensor([ 1.0671, -0.4925, -0.3025])\n",
            "1\n",
            "tensor([0.1619, 0.4491, 1.4020])\n",
            "1\n",
            "tensor([-0.5208, -1.1110,  0.7873])\n",
            "1\n",
            "tensor([-1.6683,  0.9600,  0.7039])\n",
            "1\n",
            "tensor([-0.6133,  1.3507, -0.8576])\n",
            "1\n",
            "tensor([-1.6537, -0.0220, -0.7920])\n",
            "1\n",
            "tensor([ 1.7381, -0.1327,  0.2548])\n",
            "6\n",
            "tensor([ 0.1144,  0.4471, -0.2270])\n",
            "6\n",
            "tensor([-1.3152, -0.0533, -0.3422])\n",
            "8\n",
            "tensor([ 1.0880, -0.3991,  0.5050])\n",
            "1\n",
            "tensor([ 0.4955,  0.5023, -1.3031])\n",
            "1\n",
            "tensor([0.0457, 1.4748, 0.1650])\n",
            "1\n",
            "tensor([-1.5270, -1.1556, -0.5731])\n",
            "1\n",
            "tensor([-1.8885,  0.2095,  0.4893])\n",
            "1\n",
            "tensor([-1.6497,  0.5255, -1.1890])\n",
            "1\n",
            "tensor([1.5626, 0.0837, 1.1779])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training using GradDFT and direct optimization"
      ],
      "metadata": {
        "id": "dxZTBvA_fdKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will run through the different strategies that can be used to train a Neural functional for the exchange-correlation functional in Grad DFT. Using molecules such as ethanol as training molecules, we will study how a neural functional can generalize to calculating the total energy.\n",
        "\n"
      ],
      "metadata": {
        "id": "O4rgURs9f2Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "import math\n",
        "import pdb\n",
        "\n",
        "from grad_dft import (\n",
        "\tenergy_predictor,\n",
        "\tsimple_energy_loss,\n",
        "\tNeuralFunctional,\n",
        "\tmolecule_from_pyscf,\n",
        "  Functional\n",
        ")\n",
        "\n",
        "from pyscf import gto, dft\n",
        "\n",
        "from jax.nn import sigmoid, gelu\n",
        "from jax.random import PRNGKey\n",
        "from jax import value_and_grad\n",
        "from flax import linen as nn\n",
        "from optax import adam, apply_updates\n",
        "from tqdm import tqdm\n",
        "from jax.flatten_util import ravel_pytree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from grad_dft import constraints\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9j6dkgRLDRBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating training/validation data and initial guesses\n",
        "\n",
        "The data were acuiqred from MD17 dataset. According to their documentation, the energies of molecules of MD17 dataset were calculated at the PBE/def2-SVP level of theory using very tight SCF convergence and very dense DFT integration grid."
      ],
      "metadata": {
        "id": "J9zkdqDJDfk1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWupQ1sYBIv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all_molecules = []\n",
        "train_molecules = []\n",
        "test_molecules = []\n",
        "ground_energies = []\n",
        "\n",
        "def generate_ethanol_variants(n_molecules):\n",
        "    # Base coordinates for ethanol\n",
        "    seed = 40\n",
        "    molecules = []\n",
        "    base_coords = [\n",
        "        \"C 0.0000 0.0000 0.0000\", \"C 0.0000 0.0000 1.5400\",\n",
        "        \"O 0.0000 0.0000 -1.4300\", \"H 0.0000 0.9300 -1.9300\",\n",
        "        \"H 0.0000 -0.9300 -1.9300\", \"H 0.0000 0.9300 2.0700\",\n",
        "        \"H 0.0000 -0.9300 2.0700\", \"H 0.9200 0.0000 1.9300\",\n",
        "        \"H -0.9200 0.0000 1.9300\"\n",
        "    ]\n",
        "\n",
        "    return molecules\n",
        "\n",
        "# Generate molecules\n",
        "n_total = 5  # Total number of molecules\n",
        "ethanol_molecules = generate_ethanol_variants(n_total)"
      ],
      "metadata": {
        "id": "Ayy0SxTIDrPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "train_molecules, test_molecules = train_test_split(ethanol_molecules, test_size=0.20, random_state=42)\n",
        "train_ground_energies, test_ground_energies = train_test_split(ground_energies, test_size=0.20, random_state=42)\n",
        "\n",
        "# Print the sizes of the resulting sets\n",
        "print(f\"Training set size: {len(train_molecules)}\")\n",
        "print(f\"Testing set size: {len(test_molecules)}\")"
      ],
      "metadata": {
        "id": "LsdmEZJ_J_nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "cjqH2R7fKUyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def energy_densities(molecule):\n",
        "    rho = molecule.density()\n",
        "    lda_e = -3/2 * (3/(4*jnp.pi))**(1/3) * (rho**(4/3)).sum(axis = 1, keepdims = True) #\n",
        "    #lda_e = jnp.concatenate([lda_e, lda_e], axis=0)\n",
        "    return lda_e\n",
        "\n",
        "def coefficient_inputs(molecule):\n",
        "    rho = molecule.density()\n",
        "    kinetic = molecule.kinetic_density()\n",
        "    return jnp.concatenate((rho, kinetic), axis=1)\n",
        "\n",
        "def coefficients(self, rhoinputs):\n",
        "    x = nn.Dense(features=2)(rhoinputs) # features = 1 means it outputs a single weight\n",
        "    #print(x)\n",
        "    #pdb.set_trace()\n",
        "    x = nn.LayerNorm()(x)\n",
        "    #print(\"coe\")\n",
        "    #print(x)\n",
        "    #print(gelu(x))\n",
        "    return gelu(x) # using gelu as activation function\n",
        "\n",
        "neuralfunctional = NeuralFunctional(coefficients, energy_densities, coefficient_inputs)"
      ],
      "metadata": {
        "id": "TPlaJ5a7KXDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 40\n",
        "key = jax.random.PRNGKey(seed)\n",
        "params_train = []\n",
        "cinputs = [coefficient_inputs(molecule) for molecule in train_molecules]\n",
        "for i in cinputs:\n",
        "  params_train.append(neuralfunctional.init(key, i))\n",
        "#predicted_energy = neuralfunctional.energy(params, molecule)"
      ],
      "metadata": {
        "id": "U3hVNAE6dofE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "CIHGFvc0jpcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "n_epochs, learning_rate, momentum = 200, 1e-2, 0.9\n",
        "optimizer = adam(learning_rate=learning_rate, b1=momentum)\n",
        "opt_state = optimizer.init(params)\n",
        "compute_energy = energy_predictor(neuralfunctional)\n",
        "trueenergy = mf.energy_tot()\n",
        "converging_energies = []\n",
        "\n",
        "@value_and_grad\n",
        "def SEloss(params, compute_energy, molecule, trueenergy):\n",
        "    predictedenergy, fock_matrix = compute_energy(params, molecule) #returns both the xc and fock matrix\n",
        "    converging_energies.append(predictedenergy)\n",
        "    return (predictedenergy - trueenergy) ** 2 #sqaured error used"
      ],
      "metadata": {
        "id": "SLpnmp05jtpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n"
      ],
      "metadata": {
        "id": "6nPmhekXcMZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiLN514mcPYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}